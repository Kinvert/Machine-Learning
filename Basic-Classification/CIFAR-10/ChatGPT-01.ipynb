{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f86e66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "391/391 [==============================] - 6s 12ms/step - loss: 1.8372 - accuracy: 0.4376 - val_loss: 2.7097 - val_accuracy: 0.2484\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 1.1598 - accuracy: 0.6120 - val_loss: 0.9843 - val_accuracy: 0.6591\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.9360 - accuracy: 0.6805 - val_loss: 0.9005 - val_accuracy: 0.6932\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.8101 - accuracy: 0.7206 - val_loss: 0.7868 - val_accuracy: 0.7329\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.7248 - accuracy: 0.7497 - val_loss: 0.7775 - val_accuracy: 0.7352\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.6697 - accuracy: 0.7686 - val_loss: 0.8467 - val_accuracy: 0.7204\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.6119 - accuracy: 0.7862 - val_loss: 0.6673 - val_accuracy: 0.7735\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.5742 - accuracy: 0.8006 - val_loss: 0.5797 - val_accuracy: 0.8002\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.5320 - accuracy: 0.8148 - val_loss: 0.5878 - val_accuracy: 0.7971\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.5053 - accuracy: 0.8259 - val_loss: 0.5934 - val_accuracy: 0.8001\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.4715 - accuracy: 0.8363 - val_loss: 0.6099 - val_accuracy: 0.7995\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.4438 - accuracy: 0.8449 - val_loss: 0.5161 - val_accuracy: 0.8241\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.4211 - accuracy: 0.8545 - val_loss: 0.5759 - val_accuracy: 0.8107\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.4020 - accuracy: 0.8567 - val_loss: 0.5565 - val_accuracy: 0.8239\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.3836 - accuracy: 0.8646 - val_loss: 0.5054 - val_accuracy: 0.8299\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.3687 - accuracy: 0.8696 - val_loss: 0.5279 - val_accuracy: 0.8305\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.3517 - accuracy: 0.8761 - val_loss: 0.5021 - val_accuracy: 0.8355\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.3333 - accuracy: 0.8811 - val_loss: 0.5090 - val_accuracy: 0.8291\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.3240 - accuracy: 0.8845 - val_loss: 0.4966 - val_accuracy: 0.8430\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.3100 - accuracy: 0.8892 - val_loss: 0.5143 - val_accuracy: 0.8348\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2985 - accuracy: 0.8924 - val_loss: 0.5015 - val_accuracy: 0.8422\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2882 - accuracy: 0.8982 - val_loss: 0.4874 - val_accuracy: 0.8451\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2805 - accuracy: 0.8987 - val_loss: 0.5134 - val_accuracy: 0.8380\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2712 - accuracy: 0.9027 - val_loss: 0.5323 - val_accuracy: 0.8409\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2601 - accuracy: 0.9061 - val_loss: 0.5014 - val_accuracy: 0.8472\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2524 - accuracy: 0.9095 - val_loss: 0.5010 - val_accuracy: 0.8495\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2498 - accuracy: 0.9101 - val_loss: 0.5202 - val_accuracy: 0.8422\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2373 - accuracy: 0.9157 - val_loss: 0.5326 - val_accuracy: 0.8417\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2335 - accuracy: 0.9163 - val_loss: 0.5285 - val_accuracy: 0.8473\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2272 - accuracy: 0.9192 - val_loss: 0.5298 - val_accuracy: 0.8444\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2202 - accuracy: 0.9212 - val_loss: 0.5800 - val_accuracy: 0.8368\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2137 - accuracy: 0.9226 - val_loss: 0.5159 - val_accuracy: 0.8536\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2073 - accuracy: 0.9245 - val_loss: 0.4976 - val_accuracy: 0.8489\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2073 - accuracy: 0.9258 - val_loss: 0.5754 - val_accuracy: 0.8260\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2053 - accuracy: 0.9258 - val_loss: 0.5119 - val_accuracy: 0.8441\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1993 - accuracy: 0.9294 - val_loss: 0.5217 - val_accuracy: 0.8491\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1973 - accuracy: 0.9282 - val_loss: 0.5244 - val_accuracy: 0.8462\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1876 - accuracy: 0.9326 - val_loss: 0.5615 - val_accuracy: 0.8441\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1860 - accuracy: 0.9323 - val_loss: 0.5490 - val_accuracy: 0.8447\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1831 - accuracy: 0.9350 - val_loss: 0.5128 - val_accuracy: 0.8603\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1806 - accuracy: 0.9350 - val_loss: 0.5487 - val_accuracy: 0.8439\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1706 - accuracy: 0.9383 - val_loss: 0.5449 - val_accuracy: 0.8481\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1727 - accuracy: 0.9385 - val_loss: 0.5645 - val_accuracy: 0.8451\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1686 - accuracy: 0.9403 - val_loss: 0.5228 - val_accuracy: 0.8545\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1664 - accuracy: 0.9392 - val_loss: 0.5379 - val_accuracy: 0.8551\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1650 - accuracy: 0.9403 - val_loss: 0.5502 - val_accuracy: 0.8568\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1600 - accuracy: 0.9426 - val_loss: 0.5138 - val_accuracy: 0.8591\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1571 - accuracy: 0.9433 - val_loss: 0.5879 - val_accuracy: 0.8480\n",
      "Epoch 49/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1548 - accuracy: 0.9443 - val_loss: 0.5302 - val_accuracy: 0.8541\n",
      "Epoch 50/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1528 - accuracy: 0.9448 - val_loss: 0.5401 - val_accuracy: 0.8572\n",
      "Epoch 51/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1513 - accuracy: 0.9454 - val_loss: 0.5189 - val_accuracy: 0.8587\n",
      "Epoch 52/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1511 - accuracy: 0.9453 - val_loss: 0.5229 - val_accuracy: 0.8612\n",
      "Epoch 53/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1481 - accuracy: 0.9476 - val_loss: 0.5428 - val_accuracy: 0.8567\n",
      "Epoch 54/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1450 - accuracy: 0.9483 - val_loss: 0.5469 - val_accuracy: 0.8569\n",
      "Epoch 55/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1428 - accuracy: 0.9479 - val_loss: 0.5297 - val_accuracy: 0.8609\n",
      "Epoch 56/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1392 - accuracy: 0.9496 - val_loss: 0.5889 - val_accuracy: 0.8499\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1375 - accuracy: 0.9497 - val_loss: 0.5263 - val_accuracy: 0.8598\n",
      "Epoch 58/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1359 - accuracy: 0.9516 - val_loss: 0.5652 - val_accuracy: 0.8491\n",
      "Epoch 59/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1377 - accuracy: 0.9497 - val_loss: 0.5339 - val_accuracy: 0.8579\n",
      "Epoch 60/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1365 - accuracy: 0.9513 - val_loss: 0.5623 - val_accuracy: 0.8540\n",
      "Epoch 61/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1333 - accuracy: 0.9527 - val_loss: 0.5307 - val_accuracy: 0.8609\n",
      "Epoch 62/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1352 - accuracy: 0.9524 - val_loss: 0.5338 - val_accuracy: 0.8633\n",
      "Epoch 63/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1286 - accuracy: 0.9536 - val_loss: 0.5756 - val_accuracy: 0.8569\n",
      "Epoch 64/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1246 - accuracy: 0.9555 - val_loss: 0.5931 - val_accuracy: 0.8427\n",
      "Epoch 65/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1227 - accuracy: 0.9567 - val_loss: 0.5548 - val_accuracy: 0.8616\n",
      "Epoch 66/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1261 - accuracy: 0.9548 - val_loss: 0.5997 - val_accuracy: 0.8529\n",
      "Epoch 67/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1233 - accuracy: 0.9550 - val_loss: 0.5448 - val_accuracy: 0.8617\n",
      "Epoch 68/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1227 - accuracy: 0.9552 - val_loss: 0.5446 - val_accuracy: 0.8611\n",
      "Epoch 69/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1208 - accuracy: 0.9566 - val_loss: 0.5644 - val_accuracy: 0.8604\n",
      "Epoch 70/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1200 - accuracy: 0.9569 - val_loss: 0.5446 - val_accuracy: 0.8629\n",
      "Epoch 71/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1122 - accuracy: 0.9589 - val_loss: 0.5471 - val_accuracy: 0.8628\n",
      "Epoch 72/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1197 - accuracy: 0.9568 - val_loss: 0.5742 - val_accuracy: 0.8531\n",
      "Epoch 73/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1201 - accuracy: 0.9576 - val_loss: 0.5427 - val_accuracy: 0.8613\n",
      "Epoch 74/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1139 - accuracy: 0.9599 - val_loss: 0.5574 - val_accuracy: 0.8565\n",
      "Epoch 75/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1153 - accuracy: 0.9585 - val_loss: 0.5911 - val_accuracy: 0.8538\n",
      "Epoch 76/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1162 - accuracy: 0.9579 - val_loss: 0.5506 - val_accuracy: 0.8595\n",
      "Epoch 77/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1100 - accuracy: 0.9612 - val_loss: 0.5383 - val_accuracy: 0.8636\n",
      "Epoch 78/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1135 - accuracy: 0.9601 - val_loss: 0.5588 - val_accuracy: 0.8624\n",
      "Epoch 79/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1167 - accuracy: 0.9583 - val_loss: 0.5365 - val_accuracy: 0.8606\n",
      "Epoch 80/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1098 - accuracy: 0.9606 - val_loss: 0.5449 - val_accuracy: 0.8637\n",
      "Epoch 81/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1058 - accuracy: 0.9615 - val_loss: 0.5612 - val_accuracy: 0.8601\n",
      "Epoch 82/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1106 - accuracy: 0.9604 - val_loss: 0.5442 - val_accuracy: 0.8660\n",
      "Epoch 83/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1085 - accuracy: 0.9615 - val_loss: 0.5322 - val_accuracy: 0.8659\n",
      "Epoch 84/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1063 - accuracy: 0.9610 - val_loss: 0.5641 - val_accuracy: 0.8637\n",
      "Epoch 85/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1057 - accuracy: 0.9624 - val_loss: 0.5411 - val_accuracy: 0.8624\n",
      "Epoch 86/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1058 - accuracy: 0.9623 - val_loss: 0.5724 - val_accuracy: 0.8600\n",
      "Epoch 87/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1027 - accuracy: 0.9636 - val_loss: 0.5757 - val_accuracy: 0.8598\n",
      "Epoch 88/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1005 - accuracy: 0.9637 - val_loss: 0.5450 - val_accuracy: 0.8632\n",
      "Epoch 89/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1007 - accuracy: 0.9634 - val_loss: 0.5621 - val_accuracy: 0.8621\n",
      "Epoch 90/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1015 - accuracy: 0.9636 - val_loss: 0.5556 - val_accuracy: 0.8578\n",
      "Epoch 91/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.0999 - accuracy: 0.9642 - val_loss: 0.5694 - val_accuracy: 0.8611\n",
      "Epoch 92/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1016 - accuracy: 0.9634 - val_loss: 0.5613 - val_accuracy: 0.8644\n",
      "Epoch 93/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.0983 - accuracy: 0.9640 - val_loss: 0.5838 - val_accuracy: 0.8578\n",
      "Epoch 94/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.0945 - accuracy: 0.9664 - val_loss: 0.5536 - val_accuracy: 0.8638\n",
      "Epoch 95/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.0973 - accuracy: 0.9648 - val_loss: 0.5520 - val_accuracy: 0.8601\n",
      "Epoch 96/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.0968 - accuracy: 0.9649 - val_loss: 0.5384 - val_accuracy: 0.8647\n",
      "Epoch 97/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.0943 - accuracy: 0.9657 - val_loss: 0.6037 - val_accuracy: 0.8575\n",
      "Epoch 98/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.0971 - accuracy: 0.9644 - val_loss: 0.5593 - val_accuracy: 0.8629\n",
      "Epoch 99/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.0954 - accuracy: 0.9662 - val_loss: 0.6008 - val_accuracy: 0.8527\n",
      "Epoch 100/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.0946 - accuracy: 0.9658 - val_loss: 0.6169 - val_accuracy: 0.8526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c6f9b7370>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize the pixel values\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Build the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3), activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    \n",
    "    keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    \n",
    "    keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Dropout(0.4),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7656500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 16, 16, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 8, 8, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 8, 8, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                20490     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 309,290\n",
      "Trainable params: 308,394\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872f1e25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
